下面是建议写入 `outputs/daily_logs/20251113.md` 的今日报告内容。

---

# 2025-11-13 LAM3 Daily Experiment Log

## 1. Overview

* Responsible: JsW
* Branch: `feat/feasibility`
* Models: LLaVA-1.5-7B, IDEFICS2-8B
* New Components:

  * 抽象基类：`src/models/base.MLLM`
  * 多模态 wrapper 对齐：`Llava15Wrapper`、`Idefics2Wrapper` 继承 `MLLM`
  * 毒性评测模块：`src/metrics/toxicity_providers.py` + `src/metrics/toxicity.py`
* Dataset: `data/mini_bench`（用于 smoke test）
* Goal of the day:

  1. 抽象统一 MLLM 接口，为后续 cross-attention 梯度攻击预留扩展点；
  2. 搭建可插件化的毒性（Toxicity）评测管线，并在离线环境下至少打通一个 provider；
  3. 确认 `feat/feasibility` 分支在服务器上可用，并将配置/脚本同步到远端仓库。

---

## 2. Parameters & Settings

### 2.1 Runtime（生成相关）

| Category  | Key                             | Value  | Notes                        |
| --------- | ------------------------------- | ------ | ---------------------------- |
| Precision | `precision`                     | `bf16` | 仅非量化分支生效                     |
| Device    | `device_map`                    | `auto` | 与 `device` 二选一，当前配置为 auto    |
| Gen       | `GenCfg.max_new_tokens`         | `256`  | 两模型统一上限                      |
| Gen       | `GenCfg.min_new_tokens`         | `64`   | 目前未真实传入 `.generate()`        |
| Gen       | `GenCfg.do_sample`              | `true` | wrapper 内部可覆盖（LLaVA 现强制关闭采样） |
| Gen       | `GenCfg.temperature`            | `0.2`  | 仅 `do_sample=True` 时生效       |
| Gen       | `GenCfg.top_p`                  | `0.95` | 同上                           |
| Seed      | `seed`                          | `42`   | 全局随机种子                       |
| Quant     | `quantization.enabled`          | `true` | 统一量化开关                       |
| Quant     | `quantization.compute_dtype`    | `bf16` | bnb 计算精度                     |
| Quant     | `quantization.quant_type`       | `nf4`  | 4bit 量化方案                    |
| Quant     | `quantization.use_double_quant` | `true` | 双重量化                         |

### 2.2 Toxicity（评测相关，代码默认超参数）

模块：`src/metrics/toxicity.py` + `src/metrics/toxicity_providers.py`

`ToxicityConfig` 默认字段（代码层面）：

| Field                        | Default                | Notes                                        |
| ---------------------------- | ---------------------- | -------------------------------------------- |
| `provider`                   | 必填（无默认）                | `perspective` / `openai` / `detoxify` / `hf` |
| `threshold`                  | `50`                   | 0–100，≥ threshold 记为 toxic                   |
| `batch_size`                 | `16`                   | CLI 批量评测                                     |
| `max_retries`                | `5`                    | API 失败的退避重试                                  |
| `timeout_s`                  | `30`                   | 单请求超时                                        |
| `rate_limit.perspective_qps` | `1`                    | 防止 Perspective QPS 超限                        |
| `rate_limit.openai_rps`      | `10`                   | OpenAI Moderation 限速                         |
| `hf.model_name`              | `"unitary/toxic-bert"` | HF 本地/在线分类器缺省模型                              |
| `detoxify.variant`           | `"original"`           | Detoxify 默认 variant                          |

当前实际部署状态（服务器侧）：

* Perspective：未申请 `PERSPECTIVE_API_KEY`，无法调用远程 API。
* OpenAI：已申请 `OPENAI_API_KEY`，但服务器无外网，无法连通 `api.openai.com`。
* Detoxify：模型已下载到本地并成功加载，可在当前环境下完成毒性打分。
* HF pipeline：代码已就绪，尚未在本机做系统性测试（默认应走 CPU）。

---

## 3. Observations / Results

1. **统一 MLLM 抽象层**

   * 新增 `src/models/base.py`，定义抽象基类 `MLLM`：

     * 必需方法：`generate(image, prompt, gen_cfg) -> str`
     * 扩展方法：`generate_with_trace(...) -> dict`，默认包装 `generate` 输出，将来可在各 wrapper 中重写以返回 logits / cross-attention / 中间激活等。
   * `Llava15Wrapper` 与 `Idefics2Wrapper` 均已继承 `MLLM`，当前主要实现 `generate`，为后续“攻击+梯度跟踪”预留统一入口。

2. **LLaVA-1.5-7B wrapper 收敛**

   * 统一使用 `GenCfg`（来自 `src/utils/runtime.py`），避免重复定义。
   * 内部强制：

     * 基于 `AutoProcessor.apply_chat_template` 构造标准对话格式（含 `<image>` 占位）。
     * 加入 `system` 消息，对模型行为进行约束（“只描述可见内容，不额外推断”），用于抑制明显幻觉。
     * 生成阶段仍采用**确定性解码**（`do_sample=False, temperature=1.0, top_p=1.0`），只根据 `GenCfg.max_new_tokens` 控制长度。
     * 输出后处理：剥离前缀 `Assistant:`、按 `User:` / `<|eot_id|>` / `<|end_of_text|>` 等标记截断下一轮对话，仅保留前两段回复，避免跑题与冗长续写。

3. **IDEFICS2-8B wrapper 收敛**

   * 同样基于统一 `GenCfg`；使用 `Idefics2Processor`（官方推荐） + `apply_chat_template` 构造 `"text + image"` 的消息序列。
   * 量化路径使用 `BitsAndBytesConfig(load_in_4bit=True, quant_type=nf4, compute_dtype=bf16)`，`device_map=None` 交由 HF/accelerate 做单卡放置。
   * 保留 SDPA、TF32、`cudnn.benchmark=True` 等性能优化，以及图像短边统一缩放为 `image_short_edge`（默认 336）。

4. **Toxicity 评测模块初步打通**

   * `toxicity_providers.py` 实现四类 provider：

     * `PerspectiveClient`：支持属性列表配置、QPS 限流、`backoff` 自动重试。
     * `OpenAIModerationClient`：调用官方 Moderations API，基于 categories 进行启发式综合为一个 0–100 的毒性分数。
     * `DetoxifyClient`：本地加载 Detoxify 模型，输出 label→prob，`score` 取 `toxicity`（或 `toxic`）字段。
     * `HFClassifierClient`：封装 `transformers.pipeline("text-classification")`，将多 label 预测统一为 `label->prob` 字典。
   * `toxicity.py` 提供统一入口：

     * `ToxicityConfig`（pydantic）读取 YAML 配置，构造对应 provider。
     * `eval_toxicity(texts, cfg)` 返回每条文本的 JSON 记录，包含 `provider/score/is_toxic/labels/raw/text`。
     * CLI 工具：

       * `--cfg`：毒性配置 YAML。
       * `--in`：输入 JSONL（每行可为纯文本或 dict）。
       * `--key`：指定文本字段名，否则遍历常见字段 + 若干嵌套路径（兼容 OpenAI 风格 `choices[0].message.content` 等）。
       * `--out`：输出 JSONL，自动创建目录。
     * 在 Detoxify 模式下，已在本地服务器完成 smoke test，确认可以对 response 文本打分。

5. **仓库与脚本同步**

   * 将 `configs/models.yaml` / `configs/runtime.yaml`、`scripts/smoke_test_models.py`、`scripts/prepare_env.sh`、`src/utils/runtime.py`、`src/models/*.py`、`src/metrics/*.py` 等关键文件同步到 GitHub 的 `feat/feasibility` 分支，便于远端审阅与后续协作。

---

## 4. Issues & Bug Tracking

> 说明：以下仅列出**今日新增或与今日工作强相关**的议题；11-12 仍未解决的配置/量化相关 issue 继续有效，见 `20251112.md`。

| ID           | Description                                                                                        | Severity | Status  | Note                                                                            |
| ------------ | -------------------------------------------------------------------------------------------------- | -------- | ------- | ------------------------------------------------------------------------------- |
| B20251113-1  | 毒性评测依赖的远程服务（Perspective / OpenAI）在服务器无法连外网的前提下不可用                                                  | Medium   | Blocked | 目前实际可用 provider 仅有 `detoxify`（以及理论上的 `hf` 本地模型）；需后续在可联网环境单独跑一轮对比实验。             |
| B20251113-2  | `PerspectiveClient` / `OpenAIModerationClient` 直接从 `os.environ` 读取 API key，若未设置会抛出 KeyError，缺乏优雅降级 | Medium   | Open    | 建议在 `build_client` 中增加更友好的报错信息或回退到本地 provider（detoxify/hf），并在 CLI 层打印明确提示。      |
| B20251113-3  | Toxicity CLI 尚未将配置快照（如 `cfg`、provider 名称）与输入日志路径写入输出文件头部或单独 metadata                               | Low      | Open    | 建议为每次评测在同目录写入一个 `*_meta.json`，记录 config 路径、provider、threshold 等，便于后续追溯。         |
| B20251113-4  | `DetoxifyClient` / `HFClassifierClient` 未显式设置 `device`，默认可能落在 CPU，长文本/大批量时速度较慢                     | Medium   | Open    | 短期可以通过环境变量或 CLI 选项指定 `cuda:0`，并在 serverside 文档中提示。                              |
| B20251113-5  | `MLLM.generate_with_trace()` 目前只是简单包装 `generate`，尚未暴露 cross-attention / logits 等梯度攻击所需中间量          | Medium   | Open    | 后续在实现 cross-attention 梯度攻击时，需要为 LLaVA / IDEFICS2 分别扩展该方法，返回 token-level 表示与注意力。 |
| B20251112-5  | `registry.build_model()` 尚未透传 `models.yaml.revision`                                               | Medium   | Open    | 与昨日相同，建议 `from_pretrained(..., revision=...)`，并将实际 revision 记录到日志。              |
| B20251112-8  | IDEFICS2 `processor` 未设置 `local_files_only`，在完全离线环境下有潜在失败风险                                        | Medium   | Open    | 需要在 README 中说明预缓存流程，或根据运行模式加开关。                                                 |
| B20251112-12 | IDEFICS2 量化分支 `device_map=None` 对 HF/accelerate 版本有依赖，设备放置不完全可控                                    | Medium   | Open    | 建议改为显式 `device_map="auto"` 或 `{"": self._device}`，与 `normalize_runtime` 策略对齐。   |

---

## 5. Next Actions

1. **Toxicity 评测链路完善**

   * 在 `configs/` 下新增 `toxicity_detoxify.yaml` / `toxicity_hf.yaml` 等配置示例，固定 `provider/threshold/batch_size` 等参数，并在 README 中示范调用命令。
   * 在有外网环境的机器上（或本地开发机）单独运行 Perspective / OpenAI 的完整链路，生成一份小规模对比结果（Detoxify vs Perspective/OpenAI），为后续指标设计提供参考。
   * 为 detoxify/hf provider 增加 `device` 参数暴露，允许在 CLI 通过 `--device cuda:0` 等方式控制。

2. **MLLM 抽象与攻击接口**

   * 为 LLaVA / IDEFICS2 设计 `generate_with_trace` 的扩展版本，规划返回字段（例如：`{"output", "logits", "attn", "hidden_states"}`），尽量统一键名，方便后续攻击算法在不同模型间复用。
   * 在 `scripts` 中增加一个简单 demo（不涉及梯度，仅 forward）验证 trace 接口能稳定工作且不会引入显存泄漏。

3. **配置与环境可追溯性**

   * 在所有 CLI 工具（包括 `smoke_test_models.py` 和 `toxicity.py`）的输出目录中，写入：

     * 原始命令行（`cmd.txt`）；
     * 使用的 config YAML 复制或路径；
     * 环境信息（可直接复用 `prepare_env.sh` 中的 Torch/Python 打印逻辑）。
   * 为 `prepare_env.sh` 后续增加 `pip freeze > outputs/env/pip_freeze_YYYYMMDD.txt`，在日报中记录该文件路径。

4. **开放 issue 清理**

   * 继续推进 `20251112.md` 中列出的运行时相关 issue（revision 透传、`device_kwargs` 归宿、`min_new_tokens` 是否启用等），避免在后续攻击实验阶段再回头修配置。

---

## 6. Commit & Sync

* Git Branch: `feat/feasibility`
* Git Commit: `TBD（可由实际 HEAD 填写）`
* Log File: `outputs/daily_logs/20251113.md`
* Timestamp: `2025-11-13 JST`

---
